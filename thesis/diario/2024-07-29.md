---
title: "Diario"
author: "Carlo Rosso"
date: 2024-07-29
---

Dal momento che non sono riuscito ad allenare roBERTa con l'interpretation
layer, provo a seguire il seguente paper
[[https://paperswithcode.com/paper/fine-grained-sentiment-classification-using]],
che usa bert base per fare sentiment analysis. Se riesco a implementare il
modello e ad allenarlo allora dovrei ottnere un'accuratezza del 53%.  
Ci mette più o meno 1h per epoca.
Ho scoperto una cosa dell'M1: parallelizza i calcoli su più CPU e conta il tempo
nella CPU come somma dei tempi di tutte le CPU. In particolare questo rende
l'allenamento circa 3.5 volte più veloce.

Mentre BERT si allena:
1. penso ad un'architettura personalizzata che include il transformer
2. implemento il codice del modello che ho in mente
3. penso all'indice della tesi 
4. definisco la bibliografia per quello che ho letto finora
5. ne comincio la stesura

---

## BERT base

Implementando la versine di base di bert, l'allenamento ha preso circa 3h e dopo
3 epoche con l'architettura specificata nel paper, ho ottenuto un'accuratezza
del 53.1%, confermando i risultati del paper. Risulta interessante notare che
l'accuratezza sul dev set nelle tre epoche è di 46.0%, 50.9% e 50.8%, mostrando
che con la terza epoca il modello sembra che inizi a overfittare, quando invece
l'accuratezza sul test set è di 52.6079%.  
Notando che avevo allenato il modello e avevo ottenuto un'accuratezza del 53.1%,
però non ho salvato il modello, quindi l'ho dovuto riallenare. Questi risultati
confermano il paper.

---

Struttura della tesi:

1. Ringraziamenti
2. Sommario
3. Introduzione
4. Notazione
5. Stato dell'arte (Related Work) -> commento alla bibliografia
6. RNN
7. Tree Kernel
8. Transformer (BERT)
9. Architettura personalizzata (eventualmente)
10. Bibliografia

 Ho completato la bibliografia della tesi.

---

A partire da BERT base ho implementato self-explainable BERT, ottenendo
un'accuratezza del 51.99% dopo 3 epoche, questo risultato sembra non confermare
quanto riportato nel paper, nel quale risulta che l'accuratezza dovrebbe
aumentare di circa l'1% rispetto al modello di base. Questo risultato potrebbe
essere dovuto ad una diversa implementazione del modello; comunque credo che 
provando a cambiare gli iperparametri potrei ottenere risultati migliori, in 
modo tale che siano confermati i risultati del paper.
In ogni caso, l'architettura proposta aumenta notevolmente la complessità del 
modello. Infatti il tempo di allenamento aumenta di circa 10
volte: il modello ha impiegato circa 35h per 3 epoche.  Per questo motivo ho 
deciso di non testare ulteriormente questa architettura.
