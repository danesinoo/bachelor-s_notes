---
title: "Diario"
author: "Carlo Rosso"
date: 2024-07-17
---

- trovare materiale di studio dei transformer
- degli llm

---

hybrid -> very slow, about 4h per model
       -> classification not working

normalizing the data makes the training slower (1.5x)

---

Ho studiato il seguente paper:
- [[https://paperswithcode.com/paper/bp-transformer-modelling-long-range-context]]

Voglio provare ad approfondire anche i seguenti:
- [[https://paperswithcode.com/paper/star-transformer]]
- [[https://paperswithcode.com/paper/fine-grained-sentiment-classification-using]]

---

Ho allenato i modelli per i seguenti kernel:
- -1 - funziona poly, radial, reranking, sigmoid
- 0 - funziona poly, radial, reranking, sigmoid
- 1 - funziona poly, radial, reranking, sigmoid
- 2 - funziona poly, radial, reranking, sigmoid -> fin'ora il migliore
- 3 - non funziona la classificazione
- 4 - non funziona la classificazione

---

## 0

- si potrebbe riallenare per reranking con decay in 0.2, 0.25

## 2

- si potrebbe riallenare per reranking con decay in 0.2, 0.25
