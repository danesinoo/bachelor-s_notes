---
title: "Diario"
author: "Carlo Rosso"
date: 2024-08-22
---

- [x] ripercorrere il modo in cui ho studiato i transformer: Ã¨ passato un po' di
  tempo

  - bp transformer
  - star transformer
  - bert
  - deep contextualized word representations
  - self-explain structures improve nlp models


- [x] spiegare i transformer
    - [x] introduzione -> aggiungere le citazioni
    - [x] architettura
    - [x] attention
    - [x] multi-head attention
    - [x] feed forward

- [ ] confronto dei dati

---

Allenando bert su colab si risparmia molto tempo: impiega 10min l'allenamento.
lr = 2e-5
batch size = 32
weight decay = 0.1
epochs = 3
Accuracy: 0.35158371040723985
Confusion Matrix:
[[ 12 193   3  51  20]
 [ 11 397  18 184  23]
 [  6 215  12 137  19]
 [  1 178  13 253  65]
 [  1  95   6 194 103]]

---

lr = 2e-5
batch size = 16
weight decay = 0.1
epochs = 3
Accuracy: 0.38054298642533935
Confusion Matrix:
[[ 69 136  24  34  16]
 [ 67 321  96 134  15]
 [ 26 147  68 133  15]
 [ 15 103  59 247  86]
 [ 13  41  22 187 136]]

---

lr = 2e-5
batch size = 32
weight decay = 0.1
epochs = 1
Accuracy: 0.3588235294117647
Confusion Matrix:
[[115 102  21  28  13]
 [145 255 111  88  34]
 [ 62 120  70 110  27]
 [ 46  97  62 202 103]
 [ 24  40  30 154 151]]

---

lr = 2e-5
batch size = 16
weight decay = 0.1
epochs = 1
Accuracy: 0.3597285067873303
Confusion Matrix:
[[107  91  29  41  11]
 [137 229 107 127  33]
 [ 57  97  77 134  24]
 [ 38  75  61 225 111]
 [ 23  28  29 162 157]]

---

lr = 2e-5
batch size = 16
weight decay = 0.01
epochs = 3
Accuracy: 0.36470588235294116
Confusion Matrix:
[[ 99  97  46  27  10]
 [123 244 152  90  24]
 [ 45 107 111 105  21]
 [ 27  86  92 213  92]
 [ 25  26  49 160 139]]

---

learning_rate=2e-4,
batch size=8,
num_train_epochs=2,
weight decay=0.1,
Accuracy: 0.23076923076923078
Confusion Matrix:
[[  0   0   0 279   0]
 [  0   0   0 633   0]
 [  0   0   0 389   0]
 [  0   0   0 510   0]
 [  0   0   0 399   0]]

---

{"{'lr': 0.0001, 'batch_size': 16, 'model_name': 'bert-base-uncased'}": 0.4710407257080078, 
"{'lr': 1e-05, 'batch_size': 16}": 0.5239819288253784, 
"{'lr': 1e-06, 'batch_size': 16}": 0.5058823823928833, 
"{'lr': 0.0001, 'batch_size': 32}": 0.4814479649066925, 
"{'lr': 1e-05, 'batch_size': 32}": 0.5325791835784912, 
"{'lr': 1e-06, 'batch_size': 32}": 0.446153849363327}

{"{'lr': 0.0001, 'batch_size': 16}": 0.4158371090888977, 
"{'lr': 1e-05, 'batch_size': 16}": 0.5253393650054932, 
"{'lr': 1e-06, 'batch_size': 16}": 0.459276020526886, 
"{'lr': 0.0001, 'batch_size': 32}": 0.5194570422172546, 
"{'lr': 1e-05, 'batch_size': 32}": 0.5266968607902527, 
"{'lr': 1e-06, 'batch_size': 32}": 0.4696832597255707}

distilBert

{"{'lr': 0.0001, 'batch_size': 16}": 0.4570135772228241, 
"{'lr': 1e-05, 'batch_size': 16}": 0.5140271782875061, 
"{'lr': 1e-06, 'batch_size': 16}": 0.4859728515148163, 
"{'lr': 0.0001, 'batch_size': 32}": 0.4995475113391876, 
"{'lr': 1e-05, 'batch_size': 32}": 0.5185520648956299, 
"{'lr': 1e-06, 'batch_size': 32}": 0.4633484184741974}

{"{'lr': 0.0001, 'batch_size': 16, 'model_name': 'distilbert-base-uncased'}": 0.4429864287376404, 
"{'lr': 1e-05, 'batch_size': 16, 'model_name': 'distilbert-base-uncased'}": 0.5203620195388794, 
"{'lr': 1e-06, 'batch_size': 16, 'model_name': 'distilbert-base-uncased'}": 0.4791855216026306, 
"{'lr': 0.0001, 'batch_size': 32, 'model_name': 'distilbert-base-uncased'}": 0.4837104082107544, 
"{'lr': 1e-05, 'batch_size': 32, 'model_name': 'distilbert-base-uncased'}": 0.5140271782875061, 
"{'lr': 1e-06, 'batch_size': 32, 'model_name': 'distilbert-base-uncased'}": 0.4552036225795746}

Roberta-base con l'inizializzazione del modello corretta

{"{'lr': 0.0001, 'batch_size': 16}": 0.23076923191547394, 
"{'lr': 1e-05, 'batch_size': 16}": 0.5466063618659973, 
"{'lr': 1e-06, 'batch_size': 16}": 0.5466063618659973, 
"{'lr': 0.0001, 'batch_size': 32}": 0.49683257937431335, 
"{'lr': 1e-05, 'batch_size': 32}": 0.5656108856201172, 
"{'lr': 1e-06, 'batch_size': 32}": 0.5253393650054932}

{"{'lr': 0.0001, 'batch_size': 16, 'model_name': 'roberta-base'}": 0.23076923191547394, 
"{'lr': 1e-05, 'batch_size': 16, 'model_name': 'roberta-base'}": 0.5674208402633667, 
"{'lr': 1e-06, 'batch_size': 16, 'model_name': 'roberta-base'}": 0.5457013845443726, 
"{'lr': 0.0001, 'batch_size': 32, 'model_name': 'roberta-base'}": 0.5176470875740051, 
"{'lr': 1e-05, 'batch_size': 32, 'model_name': 'roberta-base'}": 0.5733031630516052, 
"{'lr': 1e-06, 'batch_size': 32, 'model_name': 'roberta-base'}": 0.5298642516136169}
