\section{Conclusioni}

\subsection{Sentiment vs Syntax vs Subtree}

I modelli allenati sulla sintassi hanno mostrato prestazioni inferiori 
rispetto agli altri due approcci. Questa differenza è particolarmente evidente 
nell'analisi su tutti i nodi dell'albero. Tale risultato è prevedibile dato 
che il treebank di test utilizza etichette di riferimento non incluse
nel treebank di allenamento dei modelli, rendendo il confronto meno rilevante.\\
Nonostante ciò, anche limitando l'analisi alla radice dell'albero, i modelli 
basati sulla sintassi hanno registrato performance inferiori. Tale tendenza non 
si verifica nella regressione. \\
Al contrario, i modelli che integrano l'analisi del sentiment con quella
sintattica tendono a superare quelli basati esclusivamente sul sentiment, anche
se i risultati sono simili quando si focalizzano sulla predizione del target
alla radice dell'albero.\\
In aggiunta, i modelli allenati sui sottoalberi hanno dimostrato un'efficacia
notevolmente superiore nella classificazione dei pattern su ogni nodo, pur
mantenendo risultati comparabili a quelli dei modelli basati sul sentiment per
quanto riguarda la radice.

\subsection{Kernel Methods vs RNN}

Le tecniche basate su Kernel Methods, quando applicate ai sottoalberi, hanno
evidenziato performance superiori rispetto alle RNN. \\
Invece, le RNN si distinguono nettamente nell'identificazione dei pattern su 
ciascun nodo dell'albero rispetto modelli rimanenti (modello allenato su 
sentiment \& co.).\\
Si osserva, inoltre, che nei risultati relativi alla radice dell'albero, il
modello che combina il sentiment con i Kernel Methods supera
significativamente le RNN (0.12), evidenziando un divario maggiore di quello 
notato tra le RNN e il Kernel Method allenato sulla sintassi (0.3).

\subsection{Iperparametri}

Putroppo non è stato possibile eseguire un'analisi accurata degli iperparametri
perché il software trovato fallisce nel calcolo delle performance dei modelli
oppure non è in grado di classificare i pattern come richiesto.\\
I risultati mostrano che l'iperparametro 'W', ovvero forest sum, non è
rilevante, infatti qualunque valore assuma non influisce sulle performance del
modello.\\
La normalizzazione degli alberi tendenzialmente peggiora le performance dei 
modelli, tuttavia se il decay factor è elevato (circa 0.6) allora il modello
ottiene risultati migliori quando il pattern viene normalizzato.\\
Infine, il decay factor migliore risulta essere di 0.4.
