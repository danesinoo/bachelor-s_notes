\section{Risultati}

I risultati qui riportati sono ottenuti allenando e testando il modello di
default fornito da svmlight.

Le differenze tra i modelli sono date dai diversi dataset utilizzati
nell'allenamento. I test sono stati eseguiti con il medesimo dataset per quanto
riguarda la classificazione di ciascun nodo dell'albero; mentre ciascun modello 
è testato su un dataset con la medesima struttura del dataset di allenamento per 
valutare i modelli sulla radice dell'albero.

\subsection{Binary}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Modello} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
    \hline
    \textbf{Subtree sentiment all} & 0.98 & 0.99 & 0.99 & 0.99 \\
    \textbf{Subtree sentiment root} & 0.94 & 0.94 & 0.94 & 0.94 \\
    \hline

    \textbf{Syntax and sentiment all} & 0.96 & 0.97 & 0.95 & 0.96 \\
    \textbf{Syntax and sentiment root} & 0.94 & 0.94 & 0.94 & 0.94 \\
    \hline

    \textbf{Sentiment all} & 0.95 & 0.97 & 0.95 & 0.96 \\
    \textbf{Sentiment root} & 0.94 & 0.95 & 0.94 & 0.94 \\
    \hline

    \textbf{Syntax all} & 0.45 & 0.00 & 0.00 & 0.00 \\
    \textbf{Syntax root} & 0.74 & 0.72 & 0.78 & 0.75 \\
    \hline
    \end{tabular}
    \caption{Risultati della classificazione binaria}
\end{table}

\subsection{Regression}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|}
    \hline
    \textbf{Modello} & \textbf{Mean Absolute Error} & \textbf{Mean Squared
    Error} & \textbf{R-Squared} \\
    \hline
    \textbf{Subtree sentiment all} & - & - & - \\
    \textbf{Subtree sentiment root} & - & - & - \\
    \hline

    \textbf{Syntax and sentiment all} & 0.47 & 0.41 & -0.94 \\
    \textbf{Syntax and sentiment root} & 0.94 & 1.28 & -1.93 \\
    \hline

    \textbf{Sentiment all} & 0.61 & 0.66 & -2.14 \\
    \textbf{Sentiment root} & 1.17 & 1.95 & -3.48 \\
    \hline

    \textbf{Syntax all} & 0.49 & 0.35 & -0.65 \\
    \textbf{Syntax root} & 0.56 & 0.48 & -0.11 \\
    \hline
    \end{tabular}
    \caption{Risultati della regressione}
\end{table}

In questo caso mancano i risultati per il modello addestrato sui sottoalberi
perché non ho completato l'allenamento, che richiedeva molto tempo: l'ho fermato
a 40h di allenamento, ma non è stato sufficiente per il completamento.

\subsection{Multiclass}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Modello} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
    \hline
    \textbf{Subtree sentiment all} & 0.95 & 0.92 & 0.91 & 0.92 \\
    \textbf{Subtree sentiment root} & 0.51 & 0.50 & 0.48 & 0.49 \\
    \hline

    \textbf{Syntax and sentiment all} & 0.44 & 0.48 & 0.59 & 0.44 \\
    \textbf{Syntax and sentiment root} & 0.53 & 0.52 & 0.49 & 0.49 \\
    \hline

    \textbf{Sentiment all} & 0.40 & 0.45 & 0.56 & 0.40 \\
    \textbf{Sentiment root} & 0.54 & 0.54 & 0.50 & 0.50 \\
    \hline

    \textbf{Syntax all} & 0.18 & 0.04 & 0.20 & 0.06 \\
    \textbf{Syntax root} & 0.39 & 0.38 & 0.34 & 0.34 \\
    \hline
    \end{tabular}
    \caption{Risultati della classificazione multiclasse}
\end{table}

\subsection{RNN}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|c|c|}
    \hline
    \textbf{Modello} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
    \hline
    \textbf{RNN 50 unità nascoste all} & 0.79 & 0.65 & 0.53 & 0.57 \\
    \textbf{RNN 50 unità nascoste root} & 0.42 & 0.44 & 0.39 & 0.40 \\
    \hline

    \textbf{Subtree sentiment all} & 0.95 & 0.92 & 0.91 & 0.92 \\
    \textbf{Subtree sentiment root} & 0.51 & 0.50 & 0.48 & 0.49 \\
    \hline

    \textbf{Sentiment all} & 0.40 & 0.45 & 0.56 & 0.40 \\
    \textbf{Sentiment root} & 0.54 & 0.54 & 0.50 & 0.50 \\
    \hline
    \end{tabular}
    \caption{Risultati della classificazione multiclasse con RNN rispetto al
    kernel method}
\end{table}
 
Si noti che l'RNN e il kernel method allenato sul sentiment sono stati allenati
con lo stesso dataset. Tutti e tre i modelli qui presentati sono
stati valutati sullo stesso dataset di test.

\subsection{Confronto degli iperparametri}

Per confrontare gli iperparametri è stato utilizzato come dataset di allenamento
il treebank di Penn che ha sia le etichette sintattiche che quelle di sentiment.
L'accuratezza sulla radice dell'albero è stata calcolata sul test set che ha
sia le etichette sintattiche che quelle di sentiment. Come ho anticipato, ho
provato a testare i modelli anche su ciascun nodo dell'albero, però i modelli
che hanno decay factor diverso da 0 non sono in grado di classificare pattern
che hanno solo etichette di sentiment.

\begin{table}[h]
    \centering
    \begin{tabular}{cc|ccccc}
        \toprule
        \multicolumn{2}{c}{} & \multicolumn{4}{c}{Normalizzazione} \\
        \multicolumn{2}{c}{} & \multicolumn{2}{c}{No} & \multicolumn{2}{c}{Sì} \\
        \cmidrule{3-6}
        \multicolumn{2}{c}{} & \multicolumn{4}{c}{Forest Sum} \\
        \multicolumn{2}{c}{} & A & S & A & S \\
        \midrule
        \multirow{5}{*}{\begin{sideways}Decay factor\end{sideways}} & 0 & 12.624 & 12.624 & 12.624 & 12.624 \\
        & 0.1 & 53.981 & 53.981 & 53.755 & 53.755 \\
        & 0.2 & 54.389 & 54.389 & 53.484 & 53.484 \\
        & 0.25 & 54.434 & - & 53.619 & - \\
        & 0.3 & 54.479 & - & 53.393 & - \\
        & 0.35 & 54.524 & - & 53.167 & - \\
        & 0.4 & \textbf{54.660} & \textbf{54.660} & 53.257 & 53.257 \\
        & 0.42 & 54.479 & - & 53.167 & - \\
        & 0.45 & 54.298 & - & 53.484 & - \\
        & 0.5 & 53.891 & - & 53.755 & - \\
        & 0.6 & 51.990 & 51.990 & 53.167 & 53.167 \\
        \bottomrule
    \end{tabular}
    \caption{Tabella di comparazione degli iperparametri: percentuale di
    accuratezza sulla radice dell'albero.}
\end{table}
